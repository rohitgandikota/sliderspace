{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e315634-43fe-4d55-8dbe-ab09125ab01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, UNet2DConditionModel, StableDiffusionXLPipeline, LCMScheduler\n",
    "from diffusers.callbacks import PipelineCallback\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import glob, random, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa15c2-457b-4d04-bacd-36c942eae7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_slider_images(images, titles):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(len(images)*3, 3))\n",
    "    \n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        if len(images) == 1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes[i]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87027647-a865-4a7a-9c41-029cb743b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptSliderCallback(PipelineCallback):\n",
    "    \"\"\"\n",
    "    Enable Concept Slider after certain number of steps (set by `slider_strength`), this callback will set the LoRA scale to `0.0` or `slider_scale` based on the strength.\n",
    "\n",
    "    Use strength < 1 if you want more precise edits (recommend: .7 - .9)\n",
    "    \"\"\"\n",
    "    tensor_inputs = []\n",
    "\n",
    "    def __init__(self, slider_strength=1, slider_names=None, slider_scales=[0]):\n",
    "        super().__init__()\n",
    "        self.slider_names = slider_names\n",
    "        self.slider_scales = slider_scales\n",
    "        self.slider_strength = slider_strength\n",
    "    \n",
    "    def callback_fn(self, pipeline, step_index, timestep, callback_kwargs):\n",
    "        # Use cutoff_step_index if it's not None, otherwise use cutoff_step_ratio\n",
    "        attach_step = (\n",
    "           pipeline.num_timesteps - int(pipeline.num_timesteps * self.slider_strength)\n",
    "        )\n",
    "\n",
    "\n",
    "        # at the attach_step point start adding the slider\n",
    "        if step_index == attach_step:\n",
    "            pipe.set_adapters(self.slider_names, adapter_weights=self.slider_scales)\n",
    "\n",
    "        # after final step set the slider to 0 (there is a better implementation if we  callback_at_beginning of step exists in diffusers) \n",
    "        if step_index == pipeline.num_timesteps-1 and self.slider_strength!=1:\n",
    "            pipe.set_adapters(self.slider_names, adapter_weights=[0.]*len(self.slider_names))\n",
    "        \n",
    "        return callback_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621908bd-2f8d-499b-af5d-dd7b67951929",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "repo_name = \"tianweiy/DMD2\"\n",
    "ckpt_name = \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
    "\n",
    "\n",
    "device = 'cuda:0'\n",
    "weight_dtype = torch.bfloat16\n",
    "\n",
    "unet = UNet2DConditionModel.from_config(base_model_id, subfolder=\"unet\").to(device, weight_dtype)\n",
    "\n",
    "unet.load_state_dict(torch.load(hf_hub_download(repo_name, ckpt_name)))\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(base_model_id, unet=unet, torch_dtype=weight_dtype)\n",
    "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "pipe = pipe.to(device).to(weight_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95072d2d-f638-4f29-8c33-151e278ecc33",
   "metadata": {},
   "source": [
    "# Iterate through every slider you discovered and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512e1fc-76a6-46e1-9a0c-7309f743a951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sliderspace_path = '../trained_sliders/sdxl/robot/'\n",
    "slider_scales = [-2, -1, 0, 1, 2]\n",
    "sliderspace = glob.glob(f'{sliderspace_path}/*.pt')\n",
    "\n",
    "prompt = 'image of a robot'\n",
    "seed = random.randint(0, 2**15)\n",
    "\n",
    "active_adapters = pipe.get_active_adapters()\n",
    "[pipe.delete_adapters(s) for s in active_adapters if 'sliderspace' in s]\n",
    "\n",
    "for slider_idx, slider in enumerate(sliderspace):\n",
    "    image_list = []\n",
    "\n",
    "    # you can use your trained slider (either .pt or .safetensors file with diffusers)\n",
    "    adapter_path = slider\n",
    "    adapter_name = f'sliderspace_{slider_idx}'\n",
    "    \n",
    "    pipe.load_lora_weights(adapter_path, adapter_name=adapter_name)\n",
    "    pipe.set_adapters(adapter_name, adapter_weights=0)\n",
    "\n",
    "    \n",
    "        \n",
    "    for scale in slider_scales:\n",
    "        sliders_fn = ConceptSliderCallback(slider_strength=1, \n",
    "                                           slider_names=[adapter_name], \n",
    "                                           slider_scales=[scale])\n",
    "\n",
    "        images = pipe(prompt, \n",
    "                      num_inference_steps=4, \n",
    "                      guidance_scale=0, \n",
    "                      generator=torch.manual_seed(seed),\n",
    "                      callback_on_step_end=sliders_fn,\n",
    "                     ).images[0]\n",
    "        image_list.append(images)\n",
    "\n",
    "    print(f\"Slider {os.path.basename(slider).replace('.pt','').split('_')[-1]}\")\n",
    "    display_slider_images(image_list, slider_scales)\n",
    "    pipe.delete_adapters(adapter_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
